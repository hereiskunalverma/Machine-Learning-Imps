# ðŸ‘‹ Hello

# Facial Recognition Using OpenCV

![picture](https://upload.wikimedia.org/wikipedia/commons/d/db/Facial_Recognition22.jpg)

## Introduction

OpenCV (Open Source Computer Vision) is a popular computer vision library started by Intel in 1999. The cross-platform library sets its focus on real-time image processing and includes patent-free implementations of the latest computer vision algorithms. In 2008 Willow Garage took over support and OpenCV 2.3.1 now comes with a programming interface to C, C++, Python and Android. OpenCV is released under a BSD license so it is used in academic projects and commercial products alike.

## Face Recognition

Face recognition is an easy task for humans. Experiments in [211] have shown, that even one to three day old babies are able to distinguish between known faces. So how hard could it be for a computer? It turns out we know little about human recognition to date. Are inner features (eyes, nose, mouth) or outer features (head shape, hairline) used for a successful face recognition? How do we analyze an image and how does the brain encode it? It was shown by David Hubel and Torsten Wiesel, that our brain has specialized nerve cells responding to specific local features of a scene, such as lines, edges, angles or movement. Since we don't see the world as scattered pieces, our visual cortex must somehow combine the different sources of information into useful patterns. Automatic face recognition is all about extracting those meaningful features from an image, putting them into a useful representation and performing some kind of classification on them.

Face recognition based on the geometric features of a face is probably the most intuitive approach to face recognition. One of the first automated face recognition systems was described in [111] : marker points (position of eyes, ears, nose, ...) were used to build a feature vector (distance between the points, angle between them, ...). The recognition was performed by calculating the euclidean distance between feature vectors of a probe and reference image. Such a method is robust against changes in illumination by its nature, but has a huge drawback: the accurate registration of the marker points is complicated, even with state of the art algorithms. Some of the latest work on geometric face recognition was carried out in [33] . A 22-dimensional feature vector was used and experiments on large datasets have shown, that geometrical features alone may not carry enough information for face recognition.

The **Eigenfaces method** described in [212] took a holistic approach to face recognition: A facial image is a point from a high-dimensional image space and a lower-dimensional representation is found, where classification becomes easy. The lower-dimensional subspace is found with Principal Component Analysis, which identifies the axes with maximum variance. While this kind of transformation is optimal from a reconstruction standpoint, it doesn't take any class labels into account. Imagine a situation where the variance is generated from external sources, let it be light. The axes with maximum variance do not necessarily contain any discriminative information at all, hence a classification becomes impossible. So a class-specific projection with a Linear Discriminant Analysis was applied to face recognition in [14] . The basic idea is to minimize the variance within a class, while maximizing the variance between the classes at the same time.

Recently various methods for a local feature extraction emerged. To avoid the high-dimensionality of the input data only local regions of an image are described, the extracted features are (hopefully) more robust against partial occlusion, illumation and small sample size. Algorithms used for a local feature extraction are Gabor Wavelets ([232]), Discrete Cosinus Transform ([149]) and Local Binary Patterns ([3]). It's still an open research question what's the best way to preserve spatial information when applying a local feature extraction, because spatial information is potentially useful information.







<p>Let's get some data to experiment with first. I don't want to do a toy example here. We are doing face recognition, so you'll need some face images! You can either create your own dataset or start with one of the available face databases, <a href="http://face-rec.org/databases">http://face-rec.org/databases/</a> gives you an up-to-date overview. Three interesting databases are (parts of the description are quoted from <a href="http://face-rec.org">http://face-rec.org</a>):</p>
<ul>
<li><a href="http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html">AT&amp;T Facedatabase</a> The AT&amp;T Facedatabase, sometimes also referred to as <em>ORL Database of Faces</em>, contains ten different images of each of 40 distinct subjects. For some subjects, the images were taken at different times, varying the lighting, facial expressions (open / closed eyes, smiling / not smiling) and facial details (glasses / no glasses). All the images were taken against a dark homogeneous background with the subjects in an upright, frontal position (with tolerance for some side movement).</li>
<li><p class="startli"><a href="http://vision.ucsd.edu/content/yale-face-database">Yale Facedatabase A</a>, also known as Yalefaces. The AT&amp;T Facedatabase is good for initial tests, but it's a fairly easy database. The Eigenfaces method already has a 97% recognition rate on it, so you won't see any great improvements with other algorithms. The Yale Facedatabase A (also known as Yalefaces) is a more appropriate dataset for initial experiments, because the recognition problem is harder. The database consists of 15 people (14 male, 1 female) each with 11 grayscale images sized \(320 \times 243\) pixel. There are changes in the light conditions (center light, left light, right light), facial expressions (happy, normal, sad, sleepy, surprised, wink) and glasses (glasses, no-glasses).</p>
<p class="startli">The original images are not cropped and aligned. Please look into the <a class="el" href="../../da/d60/tutorial_face_main.html#face_appendix">Appendix </a> for a Python script, that does the job for you.</p>
</li>
<li><a href="http://vision.ucsd.edu/~leekc/ExtYaleDatabase/ExtYaleB.html">Extended Yale Facedatabase B</a> The Extended Yale Facedatabase B contains 2414 images of 38 different people in its cropped version. The focus of this database is set on extracting features that are robust to illumination, the images have almost no variation in emotion/occlusion/... . I personally think, that this dataset is too large for the experiments I perform in this document. You better use the <a href="http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html">AT&amp;T Facedatabase</a> for intial testing. A first version of the Yale Facedatabase B was used in <a class="el" href="../../d0/de3/citelist.html#CITEREF_BHK97">[14]</a> to see how the Eigenfaces and Fisherfaces method perform under heavy illumination changes. <a class="el" href="../../d0/de3/citelist.html#CITEREF_Lee05">[120]</a> used the same setup to take 16128 images of 28 people. The Extended Yale Facedatabase B is the merge of the two databases, which is now known as Extended Yalefacedatabase B.</li>
</ul>
<h3><a class="anchor" id="tutorial_face_prepare"></a>
Preparing the data</h3>
<p>Once we have acquired some data, we'll need to read it in our program. In the demo applications I have decided to read the images from a very simple CSV file. Why? Because it's the simplest platform-independent approach I can think of. However, if you know a simpler solution please ping me about it. Basically all the CSV file needs to contain are lines composed of a filename followed by a ; followed by the label (as <em>integer number</em>), making up a line like this:</p>
<div class="fragment"><div class="line">/path/to/image.ext;0</div></div><!-- fragment --><p>Let's dissect the line. /path/to/image.ext is the path to an image, probably something like this if you are in Windows: C:/faces/person0/image0.jpg. Then there is the separator ; and finally we assign the label 0 to the image. Think of the label as the subject (the person) this image belongs to, so same subjects (persons) should have the same label.</p>
<p>Download the AT&amp;T Facedatabase from AT&amp;T Facedatabase and the corresponding CSV file from at.txt, which looks like this (file is without ... of course):</p>
<div class="fragment"><div class="line">./at/s1/1.pgm;0</div><div class="line">./at/s1/2.pgm;0</div><div class="line">...</div><div class="line">./at/s2/1.pgm;1</div><div class="line">./at/s2/2.pgm;1</div><div class="line">...</div><div class="line">./at/s40/1.pgm;39</div><div class="line">./at/s40/2.pgm;39</div></div><!-- fragment --><p>Imagine I have extracted the files to D:/data/at and have downloaded the CSV file to D:/data/at.txt. Then you would simply need to Search &amp; Replace ./ with D:/data/. You can do that in an editor of your choice, every sufficiently advanced editor can do this. Once you have a CSV file with valid filenames and labels, you can run any of the demos by passing the path to the CSV file as parameter:</p>
<div class="fragment"><div class="line">facerec_demo.exe D:/data/at.txt</div></div><!-- fragment --><p>Please, see <a class="el" href="../../da/d60/tutorial_face_main.html#tutorial_face_appendix_csv">Creating the CSV File</a> for details on creating CSV file.</p>
<h2><a class="anchor" id="tutorial_face_eigenfaces"></a>
Eigenfaces  </h2>
<p>The problem with the image representation we are given is its high dimensionality. Two-dimensional \(p \times q\) grayscale images span a \(m = pq\)-dimensional vector space, so an image with \(100 \times 100\) pixels lies in a \(10,000\)-dimensional image space already. The question is: Are all dimensions equally useful for us? We can only make a decision if there's any variance in data, so what we are looking for are the components that account for most of the information. The Principal Component Analysis (PCA) was independently proposed by <a href="http://en.wikipedia.org/wiki/Karl_Pearson">Karl Pearson</a> (1901) and <a href="http://en.wikipedia.org/wiki/Harold_Hotelling">Harold Hotelling</a> (1933) to turn a set of possibly correlated variables into a smaller set of uncorrelated variables. The idea is, that a high-dimensional dataset is often described by correlated variables and therefore only a few meaningful dimensions account for most of the information. The PCA method finds the directions with the greatest variance in the data, called principal components.</p>
<h3><a class="anchor" id="tutorial_face_eigenfaces_algo"></a>
Algorithmic Description of Eigenfaces method</h3>
<p>Let \(X = \{ x_{1}, x_{2}, \ldots, x_{n} \}\) be a random vector with observations \(x_i \in R^{d}\).</p>
<ol type="1">
<li><p class="startli">Compute the mean \(\mu\)</p>
<p class="formulaDsp">
\[\mu = \frac{1}{n} \sum_{i=1}^{n} x_{i}\]
</p>
</li>
<li><p class="startli">Compute the the Covariance Matrix S</p>
<p class="formulaDsp">
\[S = \frac{1}{n} \sum_{i=1}^{n} (x_{i} - \mu) (x_{i} - \mu)^{T}`\]
</p>
</li>
<li><p class="startli">Compute the eigenvalues \(\lambda_{i}\) and eigenvectors \(v_{i}\) of \(S\)</p>
<p class="formulaDsp">
\[S v_{i} = \lambda_{i} v_{i}, i=1,2,\ldots,n\]
</p>
</li>
<li>Order the eigenvectors descending by their eigenvalue. The \(k\) principal components are the eigenvectors corresponding to the \(k\) largest eigenvalues.</li>
</ol>
<p>The \(k\) principal components of the observed vector \(x\) are then given by:</p>
<p class="formulaDsp">
\[y = W^{T} (x - \mu)\]
</p>
<p>where \(W = (v_{1}, v_{2}, \ldots, v_{k})\).</p>
<p>The reconstruction from the PCA basis is given by:</p>
<p class="formulaDsp">
\[x = W y + \mu\]
</p>
<p>where \(W = (v_{1}, v_{2}, \ldots, v_{k})\).</p>
<p>The Eigenfaces method then performs face recognition by:</p>
<ul>
<li>Projecting all training samples into the PCA subspace.</li>
<li>Projecting the query image into the PCA subspace.</li>
<li>Finding the nearest neighbor between the projected training images and the projected query image.</li>
</ul>
<p>Still there's one problem left to solve. Imagine we are given \(400\) images sized \(100 \times 100\) pixel. The Principal Component Analysis solves the covariance matrix \(S = X X^{T}\), where \({size}(X) = 10000 \times 400\) in our example. You would end up with a \(10000 \times 10000\) matrix, roughly \(0.8 GB\). Solving this problem isn't feasible, so we'll need to apply a trick. From your linear algebra lessons you know that a \(M \times N\) matrix with \(M &gt; N\) can only have \(N - 1\) non-zero eigenvalues. So it's possible to take the eigenvalue decomposition \(S = X^{T} X\) of size \(N \times N\) instead:</p>
<p class="formulaDsp">
\[X^{T} X v_{i} = \lambda_{i} v{i}\]
</p>
<p>and get the original eigenvectors of \(S = X X^{T}\) with a left multiplication of the data matrix:</p>
<p class="formulaDsp">
\[X X^{T} (X v_{i}) = \lambda_{i} (X v_{i})\]
</p>
<p>The resulting eigenvectors are orthogonal, to get orthonormal eigenvectors they need to be normalized to unit length. I don't want to turn this into a publication, so please look into <a class="el" href="../../d0/de3/citelist.html#CITEREF_Duda01">[55]</a> for the derivation and proof of the equations.</p>
<h3><a class="anchor" id="tutorial_face_eigenfaces_use"></a>
Eigenfaces in OpenCV</h3>
<p>For the first source code example, I'll go through it with you. I am first giving you the whole source code listing, and after this we'll look at the most important lines in detail. Please note: every source code listing is commented in detail, so you should have no problems following it.</p>
<p>The source code for this demo application is also available in the src folder coming with this documentation:</p>
<div class="fragment"><div class="line"><span class="comment">/*</span></div><div class="line"><span class="comment"> * Copyright (c) 2011. Philipp Wagner &lt;bytefish[at]gmx[dot]de&gt;.</span></div><div class="line"><span class="comment"> * Released to public domain under terms of the BSD Simplified license.</span></div><div class="line"><span class="comment"> *</span></div><div class="line"><span class="comment"> * Redistribution and use in source and binary forms, with or without</span></div><div class="line"><span class="comment"> * modification, are permitted provided that the following conditions are met:</span></div><div class="line"><span class="comment"> *   * Redistributions of source code must retain the above copyright</span></div><div class="line"><span class="comment"> *     notice, this list of conditions and the following disclaimer.</span></div><div class="line"><span class="comment"> *   * Redistributions in binary form must reproduce the above copyright</span></div><div class="line"><span class="comment"> *     notice, this list of conditions and the following disclaimer in the</span></div><div class="line"><span class="comment"> *     documentation and/or other materials provided with the distribution.</span></div><div class="line"><span class="comment"> *   * Neither the name of the organization nor the names of its contributors</span></div><div class="line"><span class="comment"> *     may be used to endorse or promote products derived from this software</span></div><div class="line"><span class="comment"> *     without specific prior written permission.</span></div><div class="line"><span class="comment"> *</span></div><div class="line"><span class="comment"> *   See &lt;http://www.opensource.org/licenses/bsd-license&gt;</span></div><div class="line"><span class="comment"> */</span></div><div class="line"></div><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="../../da/d47/core_8hpp.html">opencv2/core.hpp</a>&quot;</span></div><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="../../d3/dc8/face_8hpp.html">opencv2/face.hpp</a>&quot;</span></div><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="../../d4/dd5/highgui_8hpp.html">opencv2/highgui.hpp</a>&quot;</span></div><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="../../dd/d46/imgproc_8hpp.html">opencv2/imgproc.hpp</a>&quot;</span></div><div class="line"></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;fstream&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;sstream&gt;</span></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="../../d2/d75/namespacecv.html">cv</a>;</div><div class="line"><span class="keyword">using namespace </span><a class="code" href="../../d4/d48/namespacecv_1_1face.html">cv::face</a>;</div><div class="line"><span class="keyword">using namespace </span><a class="code" href="../../d8/dcc/namespacestd.html">std</a>;</div><div class="line"></div><div class="line"><span class="keyword">static</span> <a class="code" href="../../d3/d63/classcv_1_1Mat.html">Mat</a> norm_0_255(<a class="code" href="../../d4/d32/classcv_1_1__InputArray.html">InputArray</a> _src) {</div><div class="line">    <a class="code" href="../../d3/d63/classcv_1_1Mat.html">Mat</a> src = _src.<a class="code" href="../../d4/d32/classcv_1_1__InputArray.html#a9c09739ca3e0ce212e2ab8374aa2f195">getMat</a>();</div><div class="line">    <span class="comment">// Create and return normalized image:</span></div><div class="line">    <a class="code" href="../../d3/d63/classcv_1_1Mat.html">Mat</a> dst;</div><div class="line">    <span class="keywordflow">switch</span>(src.<a class="code" href="../../d3/d63/classcv_1_1Mat.html#aa11336b9ac538e0475d840657ce164be">channels</a>()) {</div><div class="line">    <span class="keywordflow">case</span> 1:</div><div class="line">        <a class="code" href="../../dc/d84/group__core__basic.html#ga1b6a396a456c8b6c6e4afd8591560d80">cv::normalize</a>(_src, dst, 0, 255, <a class="code" href="../../d2/de8/group__core__array.html#ggad12cefbcb5291cf958a85b4b67b6149fa9f0c1c342a18114d47b516a88e29822e">NORM_MINMAX</a>, <a class="code" href="../../d1/d1b/group__core__hal__interface.html#ga81df635441b21f532fdace401e04f588">CV_8UC1</a>);</div><div class="line">        <span class="keywordflow">break</span>;</div><div class="line">    <span class="keywordflow">case</span> 3:</div><div class="line">        <a class="code" href="../../dc/d84/group__core__basic.html#ga1b6a396a456c8b6c6e4afd8591560d80">cv::normalize</a>(_src, dst, 0, 255, <a class="code" href="../../d2/de8/group__core__array.html#ggad12cefbcb5291cf958a85b4b67b6149fa9f0c1c342a18114d47b516a88e29822e">NORM_MINMAX</a>, <a class="code" href="../../d1/d1b/group__core__hal__interface.html#ga88c4cd9de76f678f33928ef1e3f96047">CV_8UC3</a>);</div><div class="line">        <span class="keywordflow">break</span>;</div><div class="line">    <span class="keywordflow">default</span>:</div><div class="line">        src.<a class="code" href="../../d3/d63/classcv_1_1Mat.html#a33fd5d125b4c302b0c9aa86980791a77">copyTo</a>(dst);</div><div class="line">        <span class="keywordflow">break</span>;</div><div class="line">    }</div><div class="line">    <span class="keywordflow">return</span> dst;</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keyword">static</span> <span class="keywordtype">void</span> read_csv(<span class="keyword">const</span> <span class="keywordtype">string</span>&amp; filename, vector&lt;Mat&gt;&amp; images, vector&lt;int&gt;&amp; labels, <span class="keywordtype">char</span> separator = <span class="charliteral">&#39;;&#39;</span>) {</div><div class="line">    std::ifstream file(filename.c_str(), ifstream::in);</div><div class="line">    <span class="keywordflow">if</span> (!file) {</div><div class="line">        <span class="keywordtype">string</span> error_message = <span class="stringliteral">&quot;No valid input file was given, please check the given filename.&quot;</span>;</div><div class="line">        <a class="code" href="../../db/de0/group__core__utils.html#ga5b48c333c777666e076bd7052799f891">CV_Error</a>(<a class="code" href="../../d1/d0d/namespacecv_1_1Error.html#a759fa1af92f7aa7377c76ffb142abccaaf587497af64537041ee62c04a92b755d">Error::StsBadArg</a>, error_message);</div><div class="line">    }</div><div class="line">    <span class="keywordtype">string</span> <a class="code" href="../../d6/d6e/group__imgproc__draw.html#ga7078a9fae8c7e7d13d24dac2520ae4a2">line</a>, path, classlabel;</div><div class="line">    <span class="keywordflow">while</span> (getline(file, line)) {</div><div class="line">        stringstream liness(line);</div><div class="line">        getline(liness, path, separator);</div><div class="line">        getline(liness, classlabel);</div><div class="line">        <span class="keywordflow">if</span>(!path.empty() &amp;&amp; !classlabel.empty()) {</div><div class="line">            images.push_back(<a class="code" href="../../d4/da8/group__imgcodecs.html#ga288b8b3da0892bd651fce07b3bbd3a56">imread</a>(path, 0));</div><div class="line">            labels.push_back(atoi(classlabel.c_str()));</div><div class="line">        }</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keywordtype">int</span> main(<span class="keywordtype">int</span> argc, <span class="keyword">const</span> <span class="keywordtype">char</span> *argv[]) {</div><div class="line">    <span class="comment">// Check for valid command line arguments, print usage</span></div><div class="line">    <span class="comment">// if no arguments were given.</span></div><div class="line">    <span class="keywordflow">if</span> (argc &lt; 2) {</div><div class="line">        cout &lt;&lt; <span class="stringliteral">&quot;usage: &quot;</span> &lt;&lt; argv[0] &lt;&lt; <span class="stringliteral">&quot; &lt;csv.ext&gt; &lt;output_folder&gt; &quot;</span> &lt;&lt; endl;</div><div class="line">        exit(1);</div><div class="line">    }</div><div class="line">    <span class="keywordtype">string</span> output_folder = <span class="stringliteral">&quot;.&quot;</span>;</div><div class="line">    <span class="keywordflow">if</span> (argc == 3) {</div><div class="line">        output_folder = string(argv[2]);</div><div class="line">    }</div><div class="line">    <span class="comment">// Get the path to your CSV.</span></div><div class="line">    <span class="keywordtype">string</span> fn_csv = string(argv[1]);</div><div class="line">    <span class="comment">// These vectors hold the images and corresponding labels.</span></div><div class="line">    vector&lt;Mat&gt; images;</div><div class="line">    vector&lt;int&gt; labels;</div><div class="line">    <span class="comment">// Read in the data. This can fail if no valid</span></div><div class="line">    <span class="comment">// input filename is given.</span></div><div class="line">    <span class="keywordflow">try</span> {</div><div class="line">        read_csv(fn_csv, images, labels);</div><div class="line">    } <span class="keywordflow">catch</span> (<span class="keyword">const</span> <a class="code" href="../../d1/dee/classcv_1_1Exception.html">cv::Exception</a>&amp; e) {</div><div class="line">        cerr &lt;&lt; <span class="stringliteral">&quot;Error opening file \&quot;&quot;</span> &lt;&lt; fn_csv &lt;&lt; <span class="stringliteral">&quot;\&quot;. Reason: &quot;</span> &lt;&lt; e.<a class="code" href="../../d1/dee/classcv_1_1Exception.html#a7ead458b4fc88ebca20b231383c49845">msg</a> &lt;&lt; endl;</div><div class="line">        <span class="comment">// nothing more we can do</span></div><div class="line">        exit(1);</div><div class="line">    }</div><div class="line">    <span class="comment">// Quit if there are not enough images for this demo.</span></div><div class="line">    <span class="keywordflow">if</span>(images.size() &lt;= 1) {</div><div class="line">        <span class="keywordtype">string</span> error_message = <span class="stringliteral">&quot;This demo needs at least 2 images to work. Please add more images to your data set!&quot;</span>;</div><div class="line">        <a class="code" href="../../db/de0/group__core__utils.html#ga5b48c333c777666e076bd7052799f891">CV_Error</a>(<a class="code" href="../../d1/d0d/namespacecv_1_1Error.html#a759fa1af92f7aa7377c76ffb142abccaacf93e97abba2e7defa74fe5b99e122ac">Error::StsError</a>, error_message);</div><div class="line">    }</div><div class="line">    <span class="comment">// Get the height from the first image. We&#39;ll need this</span></div><div class="line">    <span class="comment">// later in code to reshape the images to their original</span></div><div class="line">    <span class="comment">// size:</span></div><div class="line">    <span class="keywordtype">int</span> height = images[0].rows;</div><div class="line">    <span class="comment">// The following lines simply get the last images from</span></div><div class="line">    <span class="comment">// your dataset and remove it from the vector. This is</span></div><div class="line">    <span class="comment">// done, so that the training data (which we learn the</span></div><div class="line">    <span class="comment">// cv::BasicFaceRecognizer on) and the test data we test</span></div><div class="line">    <span class="comment">// the model with, do not overlap.</span></div><div class="line">    <a class="code" href="../../d3/d63/classcv_1_1Mat.html">Mat</a> testSample = images[images.size() - 1];</div><div class="line">    <span class="keywordtype">int</span> testLabel = labels[labels.size() - 1];</div><div class="line">    images.pop_back();</div><div class="line">    labels.pop_back();</div><div class="line">    <span class="comment">// The following lines create an Eigenfaces model for</span></div><div class="line">    <span class="comment">// face recognition and train it with the images and</span></div><div class="line">    <span class="comment">// labels read from the given CSV file.</span></div><div class="line">    <span class="comment">// This here is a full PCA, if you just want to keep</span></div><div class="line">    <span class="comment">// 10 principal components (read Eigenfaces), then call</span></div><div class="line">    <span class="comment">// the factory method like this:</span></div><div class="line">    <span class="comment">//</span></div><div class="line">    <span class="comment">//      EigenFaceRecognizer::create(10);</span></div><div class="line">    <span class="comment">//</span></div><div class="line">    <span class="comment">// If you want to create a FaceRecognizer with a</span></div><div class="line">    <span class="comment">// confidence threshold (e.g. 123.0), call it with:</span></div><div class="line">    <span class="comment">//</span></div><div class="line">    <span class="comment">//      EigenFaceRecognizer::create(10, 123.0);</span></div><div class="line">    <span class="comment">//</span></div><div class="line">    <span class="comment">// If you want to use _all_ Eigenfaces and have a threshold,</span></div><div class="line">    <span class="comment">// then call the method like this:</span></div><div class="line">    <span class="comment">//</span></div><div class="line">    <span class="comment">//      EigenFaceRecognizer::create(0, 123.0);</span></div><div class="line">    <span class="comment">//</span></div><div class="line">    <a class="code" href="../../d0/de7/structcv_1_1Ptr.html">Ptr&lt;EigenFaceRecognizer&gt;</a> model = <a class="code" href="../../dd/d7c/classcv_1_1face_1_1EigenFaceRecognizer.html#a5ccb5a03dd0d8fb828f17670d9d28f68">EigenFaceRecognizer::create</a>();</div><div class="line">    model-&gt;<a class="code" href="../../dd/d65/classcv_1_1face_1_1FaceRecognizer.html#ac8680c2aa9649ad3f55e27761165c0d6">train</a>(images, labels);</div><div class="line">    <span class="comment">// The following line predicts the label of a given</span></div><div class="line">    <span class="comment">// test image:</span></div><div class="line">    <span class="keywordtype">int</span> predictedLabel = model-&gt;<a class="code" href="../../dd/d65/classcv_1_1face_1_1FaceRecognizer.html#aa2d2f02faffab1bf01317ae6502fb631">predict</a>(testSample);</div><div class="line">    <span class="comment">//</span></div><div class="line">    <span class="comment">// To get the confidence of a prediction call the model with:</span></div><div class="line">    <span class="comment">//</span></div><div class="line">    <span class="comment">//      int predictedLabel = -1;</span></div><div class="line">    <span class="comment">//      double confidence = 0.0;</span></div><div class="line">    <span class="comment">//      model-&gt;predict(testSample, predictedLabel, confidence);</span></div><div class="line">    <span class="comment">//</span></div><div class="line">    <span class="keywordtype">string</span> result_message = format(<span class="stringliteral">&quot;Predicted class = %d / Actual class = %d.&quot;</span>, predictedLabel, testLabel);</div><div class="line">    cout &lt;&lt; result_message &lt;&lt; endl;</div><div class="line">    <span class="comment">// Here is how to get the eigenvalues of this Eigenfaces model:</span></div><div class="line">    <a class="code" href="../../d3/d63/classcv_1_1Mat.html">Mat</a> eigenvalues = model-&gt;<a class="code" href="../../dc/dd7/classcv_1_1face_1_1BasicFaceRecognizer.html#a2420fe146dabed5ec8eef13edfb609ab">getEigenValues</a>();</div><div class="line">    <span class="comment">// And we can do the same to display the Eigenvectors (read Eigenfaces):</span></div><div class="line">    <a class="code" href="../../d3/d63/classcv_1_1Mat.html">Mat</a> W = model-&gt;<a class="code" href="../../dc/dd7/classcv_1_1face_1_1BasicFaceRecognizer.html#a115b2f96db1b1c0daa5542dd30d01dfd">getEigenVectors</a>();</div><div class="line">    <span class="comment">// Get the sample mean from the training data</span></div><div class="line">    <a class="code" href="../../d3/d63/classcv_1_1Mat.html">Mat</a> mean = model-&gt;<a class="code" href="../../dc/dd7/classcv_1_1face_1_1BasicFaceRecognizer.html#a581afaadd1762bef79de7f89b9b96907">getMean</a>();</div><div class="line">    <span class="comment">// Display or save:</span></div><div class="line">    <span class="keywordflow">if</span>(argc == 2) {</div><div class="line">        <a class="code" href="../../d7/dfc/group__highgui.html#ga453d42fe4cb60e5723281a89973ee563">imshow</a>(<span class="stringliteral">&quot;mean&quot;</span>, norm_0_255(mean.<a class="code" href="../../d3/d63/classcv_1_1Mat.html#a4eb96e3251417fa88b78e2abd6cfd7d8">reshape</a>(1, images[0].rows)));</div><div class="line">    } <span class="keywordflow">else</span> {</div><div class="line">        <a class="code" href="../../d4/da8/group__imgcodecs.html#gabbc7ef1aa2edfaa87772f1202d67e0ce">imwrite</a>(format(<span class="stringliteral">&quot;%s/mean.png&quot;</span>, output_folder.c_str()), norm_0_255(mean.<a class="code" href="../../d3/d63/classcv_1_1Mat.html#a4eb96e3251417fa88b78e2abd6cfd7d8">reshape</a>(1, images[0].rows)));</div><div class="line">    }</div><div class="line">    <span class="comment">// Display or save the Eigenfaces:</span></div><div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; <a class="code" href="../../d7/dcc/group__core__utils__softfloat.html#gac48df53b8fd34b87e7b121fa8fd4c379">min</a>(10, W.<a class="code" href="../../d3/d63/classcv_1_1Mat.html#aa3e5a47585c9ef6a0842556739155e3e">cols</a>); i++) {</div><div class="line">        <span class="keywordtype">string</span> msg = format(<span class="stringliteral">&quot;Eigenvalue #%d = %.5f&quot;</span>, i, eigenvalues.<a class="code" href="../../d3/d63/classcv_1_1Mat.html#aa5d20fc86d41d59e4d71ae93daee9726">at</a>&lt;<span class="keywordtype">double</span>&gt;(i));</div><div class="line">        cout &lt;&lt; msg &lt;&lt; endl;</div><div class="line">        <span class="comment">// get eigenvector #i</span></div><div class="line">        <a class="code" href="../../d3/d63/classcv_1_1Mat.html">Mat</a> ev = W.<a class="code" href="../../d3/d63/classcv_1_1Mat.html#a23df02a07ffbfa4aa59c19bc003919fe">col</a>(i).<a class="code" href="../../d3/d63/classcv_1_1Mat.html#adff2ea98da45eae0833e73582dd4a660">clone</a>();</div><div class="line">        <span class="comment">// Reshape to original size &amp; normalize to [0...255] for imshow.</span></div><div class="line">        <a class="code" href="../../d3/d63/classcv_1_1Mat.html">Mat</a> grayscale = norm_0_255(ev.<a class="code" href="../../d3/d63/classcv_1_1Mat.html#a4eb96e3251417fa88b78e2abd6cfd7d8">reshape</a>(1, height));</div><div class="line">        <span class="comment">// Show the image &amp; apply a Jet colormap for better sensing.</span></div><div class="line">        <a class="code" href="../../d3/d63/classcv_1_1Mat.html">Mat</a> cgrayscale;</div><div class="line">        <a class="code" href="../../d3/d50/group__imgproc__colormap.html#gadf478a5e5ff49d8aa24e726ea6f65d15">applyColorMap</a>(grayscale, cgrayscale, <a class="code" href="../../d3/d50/group__imgproc__colormap.html#gga9a805d8262bcbe273f16be9ea2055a65ab3f207661ddf74511b002b1acda5ec09">COLORMAP_JET</a>);</div><div class="line">        <span class="comment">// Display or save:</span></div><div class="line">        <span class="keywordflow">if</span>(argc == 2) {</div><div class="line">            <a class="code" href="../../d7/dfc/group__highgui.html#ga453d42fe4cb60e5723281a89973ee563">imshow</a>(format(<span class="stringliteral">&quot;eigenface_%d&quot;</span>, i), cgrayscale);</div><div class="line">        } <span class="keywordflow">else</span> {</div><div class="line">            <a class="code" href="../../d4/da8/group__imgcodecs.html#gabbc7ef1aa2edfaa87772f1202d67e0ce">imwrite</a>(format(<span class="stringliteral">&quot;%s/eigenface_%d.png&quot;</span>, output_folder.c_str(), i), norm_0_255(cgrayscale));</div><div class="line">        }</div><div class="line">    }</div><div class="line"></div><div class="line">    <span class="comment">// Display or save the image reconstruction at some predefined steps:</span></div><div class="line">    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> num_components = <a class="code" href="../../d7/dcc/group__core__utils__softfloat.html#gac48df53b8fd34b87e7b121fa8fd4c379">min</a>(W.<a class="code" href="../../d3/d63/classcv_1_1Mat.html#aa3e5a47585c9ef6a0842556739155e3e">cols</a>, 10); num_components &lt; <a class="code" href="../../d7/dcc/group__core__utils__softfloat.html#gac48df53b8fd34b87e7b121fa8fd4c379">min</a>(W.<a class="code" href="../../d3/d63/classcv_1_1Mat.html#aa3e5a47585c9ef6a0842556739155e3e">cols</a>, 300); num_components+=15) {</div><div class="line">        <span class="comment">// slice the eigenvectors from the model</span></div><div class="line">        <a class="code" href="../../d3/d63/classcv_1_1Mat.html">Mat</a> evs = <a class="code" href="../../d3/d63/classcv_1_1Mat.html">Mat</a>(W, <a class="code" href="../../da/d35/classcv_1_1Range.html#af5a0207f6f98a69077db8e77898abc0f">Range::all</a>(), <a class="code" href="../../da/d35/classcv_1_1Range.html">Range</a>(0, num_components));</div><div class="line">        <a class="code" href="../../d3/d63/classcv_1_1Mat.html">Mat</a> projection = <a class="code" href="../../db/d59/classcv_1_1LDA.html#a69c7019a344edc5c55799c16a9fc9ada">LDA::subspaceProject</a>(evs, mean, images[0].reshape(1,1));</div><div class="line">        <a class="code" href="../../d3/d63/classcv_1_1Mat.html">Mat</a> reconstruction = <a class="code" href="../../db/d59/classcv_1_1LDA.html#acbf9949e7567e23af5f71c29fcef76d4">LDA::subspaceReconstruct</a>(evs, mean, projection);</div><div class="line">        <span class="comment">// Normalize the result:</span></div><div class="line">        reconstruction = norm_0_255(reconstruction.<a class="code" href="../../d3/d63/classcv_1_1Mat.html#a4eb96e3251417fa88b78e2abd6cfd7d8">reshape</a>(1, images[0].rows));</div><div class="line">        <span class="comment">// Display or save:</span></div><div class="line">        <span class="keywordflow">if</span>(argc == 2) {</div><div class="line">            <a class="code" href="../../d7/dfc/group__highgui.html#ga453d42fe4cb60e5723281a89973ee563">imshow</a>(format(<span class="stringliteral">&quot;eigenface_reconstruction_%d&quot;</span>, num_components), reconstruction);</div><div class="line">        } <span class="keywordflow">else</span> {</div><div class="line">            <a class="code" href="../../d4/da8/group__imgcodecs.html#gabbc7ef1aa2edfaa87772f1202d67e0ce">imwrite</a>(format(<span class="stringliteral">&quot;%s/eigenface_reconstruction_%d.png&quot;</span>, output_folder.c_str(), num_components), reconstruction);</div><div class="line">        }</div><div class="line">    }</div><div class="line">    <span class="comment">// Display if we are not writing to an output folder:</span></div><div class="line">    <span class="keywordflow">if</span>(argc == 2) {</div><div class="line">        <a class="code" href="../../d7/dfc/group__highgui.html#ga5628525ad33f52eab17feebcfba38bd7">waitKey</a>(0);</div><div class="line">    }</div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div></div><!-- fragment --><p>I've used the jet colormap, so you can see how the grayscale values are distributed within the specific Eigenfaces. You can see, that the Eigenfaces do not only encode facial features, but also the illumination in the images (see the left light in Eigenface #4, right light in Eigenfaces #5):</p>
<div class="image">
<img src="../../eigenfaces_opencv.png" alt="eigenfaces_opencv.png"/>
<div class="caption">
image</div></div>
<p> We've already seen, that we can reconstruct a face from its lower dimensional approximation. So let's see how many Eigenfaces are needed for a good reconstruction. I'll do a subplot with \(10,30,\ldots,310\) Eigenfaces:</p>
<div class="fragment"><div class="line"><span class="comment">// Display or save the image reconstruction at some predefined steps:</span></div><div class="line"><span class="keywordflow">for</span>(<span class="keywordtype">int</span> num_components = 10; num_components &lt; 300; num_components+=15) {</div><div class="line">    <span class="comment">// slice the eigenvectors from the model</span></div><div class="line">    Mat evs = Mat(W, Range::all(), Range(0, num_components));</div><div class="line">    Mat projection = LDA::subspaceProject(evs, mean, images[0].reshape(1,1));</div><div class="line">    Mat reconstruction = LDA::subspaceReconstruct(evs, mean, projection);</div><div class="line">    <span class="comment">// Normalize the result:</span></div><div class="line">    reconstruction = norm_0_255(reconstruction.reshape(1, images[0].rows));</div><div class="line">    <span class="comment">// Display or save:</span></div><div class="line">    <span class="keywordflow">if</span>(argc == 2) {</div><div class="line">        <a class="code" href="../../d7/dfc/group__highgui.html#ga453d42fe4cb60e5723281a89973ee563">imshow</a>(format(<span class="stringliteral">&quot;eigenface_reconstruction_%d&quot;</span>, num_components), reconstruction);</div><div class="line">    } <span class="keywordflow">else</span> {</div><div class="line">        <a class="code" href="../../d4/da8/group__imgcodecs.html#gabbc7ef1aa2edfaa87772f1202d67e0ce">imwrite</a>(format(<span class="stringliteral">&quot;%s/eigenface_reconstruction_%d.png&quot;</span>, output_folder.c_str(), num_components), reconstruction);</div><div class="line">    }</div><div class="line">}</div></div><!-- fragment --><p>10 Eigenvectors are obviously not sufficient for a good image reconstruction, 50 Eigenvectors may already be sufficient to encode important facial features. You'll get a good reconstruction with approximately 300 Eigenvectors for the AT&amp;T Facedatabase. There are rule of thumbs how many Eigenfaces you should choose for a successful face recognition, but it heavily depends on the input data. <a class="el" href="../../d0/de3/citelist.html#CITEREF_Zhao03">[250]</a> is the perfect point to start researching for this:</p>
<div class="image">
<img src="../../eigenface_reconstruction_opencv.png" alt="eigenface_reconstruction_opencv.png"/>
<div class="caption">
image</div></div>
